{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "network1_2_vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-yacenko/ADCM_on_yandex/blob/main/network1_2_vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:20:17.460133Z",
          "start_time": "2019-10-29T19:20:17.430563Z"
        },
        "id": "5qVjbsDi3FF9"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:20:17.980509Z",
          "start_time": "2019-10-29T19:20:17.462239Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akotxx_03FF9",
        "outputId": "58ec840f-74bd-4366-9b18-e3d55cc636de"
      },
      "source": [
        "available_models = api.info()['models'].keys()\n",
        "print('\\n'.join(available_models))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fasttext-wiki-news-subwords-300\n",
            "conceptnet-numberbatch-17-06-300\n",
            "word2vec-ruscorpora-300\n",
            "word2vec-google-news-300\n",
            "glove-wiki-gigaword-50\n",
            "glove-wiki-gigaword-100\n",
            "glove-wiki-gigaword-200\n",
            "glove-wiki-gigaword-300\n",
            "glove-twitter-25\n",
            "glove-twitter-50\n",
            "glove-twitter-100\n",
            "glove-twitter-200\n",
            "__testing_word2vec-matrix-synopsis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-29T19:22:12.649035Z",
          "start_time": "2019-10-29T19:20:17.984118Z"
        },
        "scrolled": false,
        "id": "ne-i108o3FF9"
      },
      "source": [
        "pretrained = api.load('word2vec-google-news-300')  # > 1.5 GB!\n",
        "#pretrained = api.load('glove-twitter-25') # 100 Mb\n",
        "VEC_SIZE = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ogUrqXzkHuw"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import random \n",
        "RND=0\n",
        "\n",
        "random.seed(RND)\n",
        "np.random.seed(RND)\n",
        "torch.manual_seed(RND)\n",
        "torch.cuda.manual_seed(RND)\n",
        "torch.backends.cudnn.deterministic = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0BGRmiunXii"
      },
      "source": [
        "#pretrained['listeners'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-12T12:42:57.847399Z",
          "start_time": "2019-09-12T12:42:57.268037Z"
        },
        "id": "Xb3R8jnKyJ8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a8ea1f-b21d-47f3-e968-546bf2ad41b5"
      },
      "source": [
        "train_source = fetch_20newsgroups(subset='train')\n",
        "test_source = fetch_20newsgroups(subset='test')\n",
        "\n",
        "print('Количество обучающих текстов', len(train_source['data']))\n",
        "print('Количество тестовых текстов', len(test_source['data']))\n",
        "print()\n",
        "print(train_source['data'][0].strip())\n",
        "\n",
        "print()\n",
        "print('Метка', train_source['target'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество обучающих текстов 11314\n",
            "Количество тестовых текстов 7532\n",
            "\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "Метка 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP2nb_t6odAU"
      },
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
        "\n",
        "\n",
        "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
        "    txt = txt.lower()\n",
        "    all_tokens = TOKEN_RE.findall(txt)\n",
        "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
        "\n",
        "\n",
        "def character_tokenize(txt):\n",
        "    return list(txt)\n",
        "\n",
        "\n",
        "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
        "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
        "\n",
        "def build_vocabulary(tokenized_texts, max_size=1000000, max_doc_freq=0.8, min_count=5, pad_word=None):\n",
        "    word_counts = collections.defaultdict(int)\n",
        "    doc_n = 0\n",
        "\n",
        "    # посчитать количество документов, в которых употребляется каждое слово\n",
        "    # а также общее количество документов\n",
        "    for txt in tokenized_texts:\n",
        "        doc_n += 1\n",
        "        unique_text_tokens = set(txt)\n",
        "        for token in unique_text_tokens:\n",
        "            word_counts[token] += 1\n",
        "\n",
        "    # убрать слишком редкие и слишком частые слова\n",
        "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
        "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
        "\n",
        "    # отсортировать слова по убыванию частоты\n",
        "    sorted_word_counts = sorted(word_counts.items(),\n",
        "                                reverse=True,\n",
        "                                key=lambda pair: pair[1])\n",
        "\n",
        "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
        "    if pad_word is not None:\n",
        "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
        "\n",
        "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
        "    if len(word_counts) > max_size:\n",
        "        sorted_word_counts = sorted_word_counts[:max_size]\n",
        "\n",
        "    # нумеруем слова\n",
        "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
        "\n",
        "    # нормируем частоты слов\n",
        "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
        "\n",
        "    return word2id, word2freq\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-12T12:43:00.294422Z",
          "start_time": "2019-09-12T12:42:57.849386Z"
        },
        "id": "1Bo86LOuyJ8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5347806c-500d-4344-ead2-41a97294948a"
      },
      "source": [
        "train_tokenized = tokenize_corpus(train_source['data'])\n",
        "test_tokenized = tokenize_corpus(test_source['data'])\n",
        "\n",
        "print(train_tokenized[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['from', 'lerxst', 'where', 'thing', 'subject', 'what', 'this', 'nntp', 'posting', 'host', 'rac3', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'there', 'could', 'enlighten', 'this', 'other', 'door', 'sports', 'looked', 'from', 'late', 'early', 'called', 'bricklin', 'doors', 'were', 'really', 'small', 'addition', 'front', 'bumper', 'separate', 'from', 'rest', 'body', 'this', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'production', 'where', 'this', 'made', 'history', 'whatever', 'info', 'have', 'this', 'funky', 'looking', 'please', 'mail', 'thanks', 'brought', 'your', 'neighborhood', 'lerxst']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gk1NLVGINcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872b8b52-42f2-42f3-bc1c-35c2f64e524e"
      },
      "source": [
        "print(len(train_source['data']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uutGq3LvK1p4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88KBd2k2qX04"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MAX_TEXT_LEN=280\n",
        "TRAIN='train'\n",
        "TEST='test'\n",
        "# Create dataset here\n",
        "class TextDataset(Dataset):\n",
        "    \"\"\"Chars dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, SRC):\n",
        "        \"\"\"   \"\"\"\n",
        "        if SRC==TRAIN:\n",
        "          self.DATA = train_source\n",
        "          self.TOKENIZED = train_tokenized\n",
        "        else:\n",
        "          self.DATA = test_source\n",
        "          self.TOKENIZED = test_tokenized\n",
        "        self.size=len(self.DATA['data'])\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.DATA['data'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        result=self.DATA['target'][idx]\n",
        "        data_item=[]\n",
        "        i=0\n",
        "        for word in self.TOKENIZED[idx]:\n",
        "          if i==MAX_TEXT_LEN: break\n",
        "          if word in pretrained.wv.vocab:\n",
        "            i+=1\n",
        "            vec_of_word=pretrained.wv[word]\n",
        "            data_item.append(vec_of_word)\n",
        "        data_item=torch.FloatTensor(data_item)\n",
        "        if i<MAX_TEXT_LEN:\n",
        "          # здесь VEC_SIZE длинна вектора. нужно наверное программно извлекать из w2vec\n",
        "          data_item=torch.cat((data_item,torch.zeros(MAX_TEXT_LEN-i, VEC_SIZE, dtype=torch.float)))\n",
        "        return data_item,result\n",
        "\n",
        "text_datasets = {x: TextDataset(x)\n",
        "                  for x in [TRAIN, TEST]}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(text_datasets[x], batch_size=100,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in [TRAIN, TEST]}\n",
        "dataset_sizes = {x: len(text_datasets[x]) for x in [TRAIN, TEST]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiIh7Ah6nfQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ff1c23-7625-4030-b385-3d080fd6beca"
      },
      "source": [
        "print(len(text_datasets))\n",
        "data_item,result=text_datasets[TRAIN][0]\n",
        "data_item,result=text_datasets[TEST][0]\n",
        "print(len(text_datasets[TRAIN]))\n",
        "print(len(text_datasets[TEST]))\n",
        "print(result)\n",
        "print(data_item.shape)\n",
        "print(data_item[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "11314\n",
            "7532\n",
            "7\n",
            "torch.Size([280, 300])\n",
            "tensor([[ 5.8105e-02, -1.7452e-04,  7.6172e-02,  ...,  1.0132e-02,\n",
            "          6.4453e-02, -2.9663e-02],\n",
            "        [-3.7598e-02,  1.1523e-01, -9.4238e-02,  ..., -4.1748e-02,\n",
            "          1.8433e-02, -1.0107e-01],\n",
            "        [-1.1572e-01,  1.6406e-01,  9.1309e-02,  ..., -2.6367e-01,\n",
            "         -2.1362e-02, -5.4443e-02],\n",
            "        ...,\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPHl7B4SSzVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e17bab1-c291-4260-9dea-3cbffd397bd8"
      },
      "source": [
        "m = nn.AdaptiveMaxPool1d(2)\n",
        "input = torch.randn(1, 5, 8)\n",
        "output = m(input)\n",
        "print(input.shape)\n",
        "print(output.shape)\n",
        "print(input)\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 8])\n",
            "torch.Size([1, 5, 2])\n",
            "tensor([[[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160,\n",
            "          -2.1152],\n",
            "         [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168,\n",
            "          -0.2473],\n",
            "         [-1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,\n",
            "           1.8530],\n",
            "         [-0.2159, -0.7425,  0.5627,  0.2596, -0.1740, -0.6787,  0.9383,\n",
            "           0.4889],\n",
            "         [ 1.2032,  0.0845, -1.2001, -0.0048, -0.5181, -0.3067, -1.5810,\n",
            "           1.7066]]])\n",
            "tensor([[[-0.2506,  0.8487],\n",
            "         [ 0.3500,  1.2377],\n",
            "         [ 0.7935,  1.8530],\n",
            "         [ 0.5627,  0.9383],\n",
            "         [ 1.2032,  1.7066]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlviXINAuvjQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "\n",
        "class DCCNet(torch.nn.Module):\n",
        "    def __init__(self,num_in=MAX_TEXT_LEN*VEC_SIZE,num_out=20):\n",
        "        super(DCCNet, self).__init__()\n",
        "        self.SHOW=0\n",
        "\n",
        "        self.flat = torch.nn.Flatten()\n",
        "        self.fc1 = torch.nn.Linear(num_in,200)\n",
        "        self.cactiv1 = torch.nn.Tanh()\n",
        "        self.fc2 = torch.nn.Linear(200,20)\n",
        "        # self.cactiv2 = torch.nn.Tanh()\n",
        "        # self.fc3 = torch.nn.Linear(20,num_out)\n",
        "        # self.sm = torch.nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x= self.flat(x)          \n",
        "        x = self.fc1(x)\n",
        "        x = self.cactiv1(x)\n",
        "        x = self.fc2(x)\n",
        "        # x = self.cactiv2(x)\n",
        "        # x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def inference(self, x):\n",
        "        x = self.forward(x)\n",
        "        #x = self.sm(x)\n",
        "        return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh1uIcwwKT80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bae5659-de00-4c9a-843e-db8d5ea58629"
      },
      "source": [
        "input = torch.randn(7, 16, 5)\n",
        "print(input.shape)\n",
        "m = nn.Conv1d(16, 1, 3)\n",
        "output = m(input)\n",
        "#print(input)\n",
        "#print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7, 16, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5mWw4F--GzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79581a3a-6ef8-457a-f241-b8ca987ffcb7"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nap9T36kvR00"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "EPOCHS=100\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=EPOCHS):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = sys.maxsize\n",
        "    best_acc = -sys.maxsize - 1 \n",
        "\n",
        "    early_stopping=0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in [TRAIN, TEST]:\n",
        "            if phase == TEST:\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == TRAIN):\n",
        "                    outputs = model.forward(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == TRAIN:\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == TRAIN:\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == TEST and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                early_stopping = early_stopping+1 if early_stopping<0 else 0\n",
        "            else:\n",
        "                early_stopping -=1\n",
        "\n",
        "\n",
        "        print()\n",
        "        if early_stopping<-7: \n",
        "          break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    str_res='Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60)+'Best val Acc: {:4f}'.format(best_acc)\n",
        "\n",
        "    # ,padding=1load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model,str_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Ljat6AwH1r"
      },
      "source": [
        "model_ft = DCCNet(MAX_TEXT_LEN*VEC_SIZE,20)\n",
        "#model_ft = models.alexnet()\n",
        "num_ftrs = model_ft.parameters()\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O357kziHwxN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b7dc5a-88b9-4bfd-8ea4-55c9392a91a4"
      },
      "source": [
        "model_ft,str_res = train_model(model_ft,criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 1.5474 Acc: 0.5327\n",
            "test Loss: 1.2419 Acc: 0.6078\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 0.1913 Acc: 0.9700\n",
            "test Loss: 1.1880 Acc: 0.6199\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 0.0393 Acc: 0.9976\n",
            "test Loss: 1.1857 Acc: 0.6294\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 0.0142 Acc: 0.9995\n",
            "test Loss: 1.2094 Acc: 0.6318\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 0.0088 Acc: 0.9994\n",
            "test Loss: 1.2311 Acc: 0.6305\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 0.0058 Acc: 0.9996\n",
            "test Loss: 1.2437 Acc: 0.6318\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 0.0043 Acc: 0.9995\n",
            "test Loss: 1.2593 Acc: 0.6326\n",
            "\n",
            "Training complete in 12m 12s\n",
            "Best val Acc: 0.629448\n"
          ]
        }
      ]
    }
  ]
}